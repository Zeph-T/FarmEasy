{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NA5gRqs6y97j"
   },
   "source": [
    "# Import Libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VUGtqDPgSmZJ"
   },
   "source": [
    "Importing necessary libraries and modules required to build the classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AMUpYwh1HpCi",
    "outputId": "fdab74cb-e272-4bbb-8744-65c20088fb45"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V_Chojawz3jw"
   },
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OyRk7kzTzOpO"
   },
   "source": [
    "Initializing a few parameters required for the image dataset preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v5eHthEdIBsr"
   },
   "outputs": [],
   "source": [
    "# Dimension of resized image\n",
    "DEFAULT_IMAGE_SIZE = tuple((256, 256))\n",
    "\n",
    "# Number of images used to train the model\n",
    "N_IMAGES = 100\n",
    "\n",
    "# Path to the dataset folder\n",
    "root_dir = '../../Datasets/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/'\n",
    "\n",
    "train_dir = os.path.join(root_dir, 'train')\n",
    "val_dir = os.path.join(root_dir, 'val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vyFL0dIxz-zk"
   },
   "source": [
    "We use the function `convert_image_to_array` to resize an image to the size `DEFAULT_IMAGE_SIZE` we defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WnCNrzC539qT"
   },
   "outputs": [],
   "source": [
    "def convert_image_to_array(image_dir):\n",
    "    try:\n",
    "        image = cv2.imread(image_dir)\n",
    "        if image is not None:\n",
    "            image = cv2.resize(image, DEFAULT_IMAGE_SIZE)   \n",
    "            return img_to_array(image)\n",
    "        else:\n",
    "            return np.array([])\n",
    "    except Exception as e:\n",
    "        print(f\"Error : {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q7uyGLRR1RaB"
   },
   "source": [
    "Here, we load the training data images by traversing through all the folders and converting all the images and labels into separate lists respectively.\n",
    "\n",
    "*NOTE: We use a small portion of the entire dataset due to the computing limitations. Tweak `N_IMAGES` to include entire dataset.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 739
    },
    "colab_type": "code",
    "id": "MPaECpW13__5",
    "outputId": "7d88fa4b-9abb-4615-db7a-797b1cb5e926"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading images ...\n",
      "[INFO] Processing Corn_(maize)___Northern_Leaf_Blight ...\n",
      "[INFO] Processing Blueberry___healthy ...\n",
      "[INFO] Processing Tomato___Leaf_Mold ...\n",
      "[INFO] Processing Potato___healthy ...\n",
      "[INFO] Processing Corn_(maize)___Common_rust_ ...\n",
      "[INFO] Processing Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot ...\n",
      "[INFO] Processing Tomato___Septoria_leaf_spot ...\n",
      "[INFO] Processing Cherry_(including_sour)___Powdery_mildew ...\n",
      "[INFO] Processing Apple___Black_rot ...\n",
      "[INFO] Processing Apple___Cedar_apple_rust ...\n",
      "[INFO] Processing Tomato___Tomato_mosaic_virus ...\n",
      "[INFO] Processing Pepper,_bell___Bacterial_spot ...\n",
      "[INFO] Processing Tomato___healthy ...\n",
      "[INFO] Processing Strawberry___healthy ...\n",
      "[INFO] Processing Tomato___Bacterial_spot ...\n",
      "[INFO] Processing Pepper,_bell___healthy ...\n",
      "[INFO] Processing Grape___Leaf_blight_(Isariopsis_Leaf_Spot) ...\n",
      "[INFO] Processing Peach___healthy ...\n",
      "[INFO] Processing Tomato___Target_Spot ...\n",
      "[INFO] Processing Orange___Haunglongbing_(Citrus_greening) ...\n",
      "[INFO] Processing Soybean___healthy ...\n",
      "[INFO] Processing Grape___healthy ...\n",
      "[INFO] Processing Tomato___Tomato_Yellow_Leaf_Curl_Virus ...\n",
      "[INFO] Processing Grape___Black_rot ...\n",
      "[INFO] Processing Strawberry___Leaf_scorch ...\n",
      "[INFO] Processing Tomato___Late_blight ...\n",
      "[INFO] Processing Apple___Apple_scab ...\n",
      "[INFO] Processing Potato___Late_blight ...\n",
      "[INFO] Processing Cherry_(including_sour)___healthy ...\n",
      "[INFO] Processing Apple___healthy ...\n",
      "[INFO] Processing Corn_(maize)___healthy ...\n",
      "[INFO] Processing Tomato___Early_blight ...\n",
      "[INFO] Processing Grape___Esca_(Black_Measles) ...\n",
      "[INFO] Processing Peach___Bacterial_spot ...\n",
      "[INFO] Processing Raspberry___healthy ...\n",
      "[INFO] Processing Squash___Powdery_mildew ...\n",
      "[INFO] Processing Potato___Early_blight ...\n",
      "[INFO] Processing Tomato___Spider_mites Two-spotted_spider_mite ...\n",
      "[INFO] Image loading completed\n",
      "\n",
      "Total number of images: 3800\n"
     ]
    }
   ],
   "source": [
    "image_list, label_list = [], []\n",
    "\n",
    "try:\n",
    "    print(\"[INFO] Loading images ...\")\n",
    "    plant_disease_folder_list = listdir(train_dir)\n",
    "\n",
    "    for plant_disease_folder in plant_disease_folder_list:\n",
    "        print(f\"[INFO] Processing {plant_disease_folder} ...\")\n",
    "        plant_disease_image_list = listdir(f\"{train_dir}/{plant_disease_folder}/\")\n",
    "\n",
    "        for image in plant_disease_image_list[:N_IMAGES]:\n",
    "            image_directory = f\"{train_dir}/{plant_disease_folder}/{image}\"\n",
    "            if image_directory.endswith(\".jpg\")==True or image_directory.endswith(\".JPG\")==True:\n",
    "                image_list.append(convert_image_to_array(image_directory))\n",
    "                label_list.append(plant_disease_folder)\n",
    "\n",
    "    print(\"[INFO] Image loading completed\")  \n",
    "except Exception as e:\n",
    "    print(f\"Error : {e}\")\n",
    "\n",
    "# Transform the loaded training image data into numpy array\n",
    "np_image_list = np.array(image_list, dtype=np.float16) / 225.0\n",
    "print()\n",
    "\n",
    "# Check the number of images loaded for training\n",
    "image_len = len(image_list)\n",
    "print(f\"Total number of images: {image_len}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WOzIsDNP3TWy"
   },
   "source": [
    "Examine the labels/classes in the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "jq5HO2SuILNk",
    "outputId": "182d992e-b353-4c79-b85f-5e4817bc3548"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of classes:  38\n"
     ]
    }
   ],
   "source": [
    "label_binarizer = LabelBinarizer()\n",
    "image_labels = label_binarizer.fit_transform(label_list)\n",
    "\n",
    "pickle.dump(label_binarizer,open('../Models/plant_disease_label_transform.pkl', 'wb'))\n",
    "n_classes = len(label_binarizer.classes_)\n",
    "\n",
    "print(\"Total number of classes: \", n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "siSjS-jG77FH"
   },
   "source": [
    "# Augment and Split Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G44Cdatx8VVN"
   },
   "source": [
    "Using `ImageDataGenerator` to augment data by performing various operations on the training images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pbIYhnSFJkjp"
   },
   "outputs": [],
   "source": [
    "augment = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
    "                             height_shift_range=0.1, shear_range=0.2, \n",
    "                             zoom_range=0.2, horizontal_flip=True, \n",
    "                             fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aaoNWFDd8swl"
   },
   "source": [
    "Splitting the data into training and test sets for validation purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0Ls-TztoQlwD",
    "outputId": "fd39d4c6-26c0-465a-923c-d8044276d395"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Splitting data to train and test...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Splitting data to train and test...\")\n",
    "x_train, x_test, y_train, y_test = train_test_split(np_image_list, image_labels, test_size=0.2, random_state = 42) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i4VNmekW4oEN"
   },
   "source": [
    "# Build Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1QUHIVIcg6qI"
   },
   "source": [
    "Defining the hyperparameters of the plant disease classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BLZkDigJ9q4X"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "STEPS = 100\n",
    "LR = 1e-3\n",
    "BATCH_SIZE = 32\n",
    "WIDTH = 256\n",
    "HEIGHT = 256\n",
    "DEPTH = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZAlqxrJzha2n"
   },
   "source": [
    "Creating a sequential model and adding Convolutional, Normalization, Pooling, Dropout and Activation layers at the appropriate positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "J_QFYYx8OVOb",
    "outputId": "102fba93-dd57-492e-9280-eec13f749d18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 256, 256, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 256, 256, 32)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 256, 256, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 85, 85, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 85, 85, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 85, 85, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 85, 85, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 85, 85, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 42, 42, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 42, 42, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 112896)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               14450816  \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 38)                4902      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 38)                0         \n",
      "=================================================================\n",
      "Total params: 14,476,006\n",
      "Trainable params: 14,475,558\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "inputShape = (HEIGHT, WIDTH, DEPTH)\n",
    "chanDim = -1\n",
    "\n",
    "if K.image_data_format() == \"channels_first\":\n",
    "    inputShape = (DEPTH, HEIGHT, WIDTH)\n",
    "    chanDim = 1\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=inputShape))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(BatchNormalization(axis=chanDim))\n",
    "# model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(BatchNormalization(axis=chanDim))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "# model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(BatchNormalization(axis=chanDim))\n",
    "# model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(n_classes))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ViKAhHPN5VMM"
   },
   "source": [
    "# Train Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "syZMhHG-iFlT"
   },
   "source": [
    "We initialize Adam optimizer with learning rate and decay parameters. \n",
    "\n",
    "Also, we choose the type of loss and metrics for the model and compile it for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 884
    },
    "colab_type": "code",
    "id": "PFRGnmHiO0Wt",
    "outputId": "410f8866-8786-4591-d71f-5a5c016e3ad9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeph/.local/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeph/.local/lib/python3.8/site-packages/keras/engine/training.py:1915: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "# Initialize optimizer\n",
    "opt = Adam(lr=LR, decay=LR / EPOCHS)\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "# Train model\n",
    "print(\"[INFO] Training network...\")\n",
    "history = model.fit_generator(augment.flow(x_train, y_train, batch_size=BATCH_SIZE),\n",
    "                              validation_data=(x_test, y_test),\n",
    "                              steps_per_epoch=len(x_train) // BATCH_SIZE,\n",
    "                              epochs=EPOCHS, \n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d6gp-hPe9Rra"
   },
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "75wjEVZ-9Yab"
   },
   "source": [
    "Comparing the accuracy and loss by plotting the graph for training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "colab_type": "code",
    "id": "68DC4UqXTH4r",
    "outputId": "ba9057e9-7f06-48e9-db10-c198e7a52ad4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BXO9rDqtNlDN"
   },
   "source": [
    "Evaluating model accuracy by using the `evaluate` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "WlvFAyeuRQPK",
    "outputId": "9d775b2b-cdee-4e34-dda6-698fbce551b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Calculating model accuracy\n",
      "24/24 [==============================] - 13s 525ms/step - loss: 0.0420 - accuracy: 0.7013\n",
      "Test Accuracy: 70.13157606124878\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Calculating model accuracy\")\n",
    "scores = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Accuracy: {scores[1]*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "02FiJNWTN5J0"
   },
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "m84g3UW4RW0j",
    "outputId": "9972543b-0d1b-4a51-9a79-15564c874f9a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: plant_disease_classification\\assets\n"
     ]
    }
   ],
   "source": [
    "# # Dump pickle file of the model\n",
    "# print(\"[INFO] Saving model...\")\n",
    "# pickle.dump(model,open('plant_disease_classification_model.h5', 'wb'))\n",
    "model.save('plant_disease_classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UkzOGExsRe3I",
    "outputId": "3bb2d4f6-8384-418a-d6b2-669bafb82ee2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving label transform...\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uxhKVIETOuah"
   },
   "outputs": [],
   "source": [
    "def predict_disease(image_path):\n",
    "    image_array = convert_image_to_array(image_path)\n",
    "    np_image = np.array(image_array, dtype=np.float16) / 225.0\n",
    "    np_image = np.expand_dims(np_image,0)\n",
    "    plt.imshow(plt.imread(image_path))\n",
    "    result = model.predict_classes(np_image)\n",
    "    print((image_labels.classes_[result][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "w2Eq3ybER2dX",
    "outputId": "7247605d-b902-41a2-d4c5-6dceeca0d1ff"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "Yx7zkdJWlLAz",
    "outputId": "f832bd93-c1cc-4187-dd6b-20917be315bf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "PJb3gtAWlgJW",
    "outputId": "d043d0a0-9fda-4f72-e41c-1a7eb003c9a9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "6SVSwms_ln3B",
    "outputId": "0c90e96a-fd53-4382-daac-e16690dce936"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "YK-FS4h-l7UW",
    "outputId": "e68d02a2-d227-4bc4-c057-4e0f371cabe4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FuyQWhlqj-jz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1_BpNjfQmgHI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_WTErOo1jigq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "LXnqW4w3mkLA",
    "outputId": "7022dace-353f-4ee8-b51c-ea45ab7956ab"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Plant Disease Classification.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
